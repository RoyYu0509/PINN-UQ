#Importing the necessary
import os
import numpy as np
import math
from tqdm import tqdm
import matplotlib as mpl
from matplotlib import pyplot as plt
from mpl_toolkits.axes_grid1 import make_axes_locatable
import pandas as pd

import torch
import torch.nn as nn
import sklearn
from sklearn.neighbors import NearestNeighbors
from utils_uq_vi import VIBPINN

from scipy.stats import norm


if torch.backends.mps.is_available():
    device = torch.device("mps")  # Apple Silicon GPU (M1/M2/M3)
elif torch.cuda.is_available():
    device = torch.device("cuda")  # NVIDIA GPU
else:
    device = torch.device("cpu")   # Fallback to CPU


def _to_numpy(x):
    "Torch → NumPy if necessary, otherwise no-op."
    if torch.is_tensor(x):
        return x.detach().cpu().numpy()
    return np.asarray(x)


def _coverage(pred_set, y_true):
    """
    Empirical coverage:  fraction of targets that fall inside the
    predicted interval.

    Parameters
    ----------
    pred_set : array-like, shape (2, N)  OR  (N, 2)
        Row/column order doesn’t matter as long as lower < upper.
    y_true   : array-like, shape (N,)

    Returns
    -------
    float   in the range [0, 1]
    """
    lower, upper = pred_set[0], pred_set[1]
    y_true = y_true.to(lower.device)
    inside = (y_true >= lower) & (y_true <= upper)
    return inside.float().mean().item()


# Define Sharpness
def _sharpness(pred_set):
    """Return the average sharpness of the UQ on the test data set

    Parameters:
        - pred_set: the prediction set generated by the model
    """
    lower = pred_set[0]
    upper = pred_set[1]

    return (upper - lower).mean().item()


# Test coverage under different level of uncertainty
def test_uncertainties(uqmodel, alphas, X_test, Y_test):
    """
        Evaluate uncertainty metrics (coverage and sharpness) over a range of alphas.

        Parameters:
            uqmodel: callable that returns (pred_set, empirical_coverage)
            alphas: list of uq uncertainty levels (CP:alpha; Drop-Out:drop_out_rate; VI:prior_std)
            X_test, Y_test: test data

        Returns:
            pandas.DataFrame with columns ["alpha", "coverage", "sharpness"]
    """
    # Test VI model
    if isinstance(uqmodel, VIBPINN):
        results = []

        def miscoverage_to_z(alpha):  # alpha in (0,1)
            return norm.ppf(1 - alpha / 2)

        for alpha in tqdm(alphas):
            alpha_val = float(alpha.item())
            if not (0.0 < alpha_val < 1.0):
                raise ValueError("alpha must be in (0,1) for VI.")
            z = miscoverage_to_z(alpha_val)
            z = torch.tensor(z, dtype=torch.float32, device=X_test.device)
            pred_set = uqmodel.predict(X_test, n_samples=100, z_score=z)
            coverage = _coverage(pred_set, Y_test)
            sha = _sharpness(pred_set)

            results.append({
                "alpha": alpha_val,
                "coverage": coverage,
                "sharpness": sha
            })

    else:
        results = []

        for alpha in tqdm(alphas):
            pred_set = uqmodel.predict(X_test, Y_test, alpha)
            coverage = _coverage(pred_set, Y_test)
            sha = _sharpness(pred_set)

            results.append({
                "alpha": alpha,
                "coverage": coverage,
                "sharpness": sha
            })

    return pd.DataFrame(results)

