#Importing the necessary
import os
import numpy as np
import math
from tqdm import tqdm
from timeit import default_timer
import matplotlib as mpl
from matplotlib import pyplot as plt
from mpl_toolkits.axes_grid1 import make_axes_locatable
import pandas as pd

import torch
import torch.nn as nn
from pyDOE import lhs
from utils import *

import sklearn
from sklearn.neighbors import NearestNeighbors
from utils_uq_vi import VIBPINN


if torch.backends.mps.is_available():
    device = torch.device("mps")  # Apple Silicon GPU (M1/M2/M3)
elif torch.cuda.is_available():
    device = torch.device("cuda")  # NVIDIA GPU
else:
    device = torch.device("cpu")   # Fallback to CPU


def _to_numpy(x):
    "Torch → NumPy if necessary, otherwise no-op."
    if torch.is_tensor(x):
        return x.detach().cpu().numpy()
    return np.asarray(x)


def _coverage(pred_set, y_true):
    """
    Empirical coverage:  fraction of targets that fall inside the
    predicted interval.

    Parameters
    ----------
    pred_set : array-like, shape (2, N)  OR  (N, 2)
        Row/column order doesn’t matter as long as lower < upper.
    y_true   : array-like, shape (N,)

    Returns
    -------
    float   in the range [0, 1]
    """
    y_np = _to_numpy(y_true)

    lower, upper = pred_set[0], pred_set[1]

    inside = (y_np >= lower) & (y_np <= upper)
    return inside.mean().item()


# Define Sharpness
def _sharpness(pred_set):
    """Return the average sharpness of the UQ on the test data set

    Parameters:
        - pred_set: the prediction set generated by the model
    """
    lower = pred_set[0]
    upper = pred_set[1]

    return (upper - lower).mean()


# Test coverage under different level of uncertainty
def test_uncertainties(uqmodel, alphas, X_test, Y_test):
    """
        Evaluate uncertainty metrics (coverage and sharpness) over a range of alphas.

        Parameters:
            uqmodel: callable that returns (pred_set, empirical_coverage)
            alphas: list of uq uncertainty levels (CP:alpha; Drop-Out:drop_out_rate; VI:prior_std)
            X_test, Y_test: test data

        Returns:
            pandas.DataFrame with columns ["alpha", "coverage", "sharpness"]
    """
    # Test VI model
    if isinstance(uqmodel, VIBPINN):
        results = []
        def z_score(conf_level):
            alpha = 1 - conf_level
            return norm.ppf(1 - alpha / 2)

        for alpha in tqdm(alphas):
            z = z_score(alphas)
            pred_set = uqmodel.predict(X_test, Y_test, z)
            coverage = _coverage(pred_set, Y_test)
            sha = _sharpness(pred_set)

            results.append({
                "alpha": alpha,
                "coverage": coverage,
                "sharpness": sha
            })

    results = []

    for alpha in tqdm(alphas):
        pred_set = uqmodel.predict(X_test, Y_test, alpha)
        coverage = _coverage(pred_set, Y_test)
        sha = _sharpness(pred_set)

        results.append({
            "alpha": alpha,
            "coverage": coverage,
            "sharpness": sha
        })

    return pd.DataFrame(results)

