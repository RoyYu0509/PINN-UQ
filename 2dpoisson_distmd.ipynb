{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c23f323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Using device: cpu\n",
      "\n",
      "[🔎] Trying: {'epochs': 100, 'λ_pde': 1.0, 'λ_ic': 5.0, 'λ_data': 1.0, 'lr': 0.001, 'stop_schedule': 20000}\n",
      "\n",
      "[🟠] Training...\n",
      "ep     1 | L=9.07e+01 | lr=1.0e-03\n",
      "\n",
      "[🟠] Inferencing...\n",
      "\n",
      "[🟠] Computing Coverage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 471.32it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 263.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[✅] Data Loss = 1.018e-02\n",
      "\n",
      "[🔎] Trying: {'epochs': 100, 'λ_pde': 1.0, 'λ_ic': 5.0, 'λ_data': 2.5, 'lr': 0.001, 'stop_schedule': 20000}\n",
      "\n",
      "[🟠] Training...\n",
      "ep     1 | L=5.79e-01 | lr=1.0e-03\n",
      "\n",
      "[🟠] Inferencing...\n",
      "\n",
      "[🟠] Computing Coverage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 397.59it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 247.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[✅] Data Loss = 6.842e-03\n",
      "\n",
      "[🔎] Trying: {'epochs': 100, 'λ_pde': 1.0, 'λ_ic': 5.0, 'λ_data': 5.0, 'lr': 0.001, 'stop_schedule': 20000}\n",
      "\n",
      "[🟠] Training...\n",
      "ep     1 | L=3.35e-01 | lr=1.0e-03\n",
      "\n",
      "[🟠] Inferencing...\n",
      "\n",
      "[🟠] Computing Coverage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 427.71it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 262.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[✅] Data Loss = 7.015e-03\n",
      "\n",
      "[🔎] Trying: {'epochs': 100, 'λ_pde': 1.0, 'λ_ic': 10.0, 'λ_data': 1.0, 'lr': 0.001, 'stop_schedule': 20000}\n",
      "\n",
      "[🟠] Training...\n",
      "ep     1 | L=2.66e-01 | lr=1.0e-03\n",
      "\n",
      "[🟠] Inferencing...\n",
      "\n",
      "[🟠] Computing Coverage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 471.31it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 214.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[✅] Data Loss = 6.842e-03\n",
      "\n",
      "[🔎] Trying: {'epochs': 100, 'λ_pde': 1.0, 'λ_ic': 10.0, 'λ_data': 2.5, 'lr': 0.001, 'stop_schedule': 20000}\n",
      "\n",
      "[🟠] Training...\n",
      "ep     1 | L=2.61e-01 | lr=1.0e-03\n",
      "\n",
      "[🟠] Inferencing...\n",
      "\n",
      "[🟠] Computing Coverage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 401.30it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 187.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[✅] Data Loss = 6.327e-03\n",
      "\n",
      "[🔎] Trying: {'epochs': 100, 'λ_pde': 1.0, 'λ_ic': 10.0, 'λ_data': 5.0, 'lr': 0.001, 'stop_schedule': 20000}\n",
      "\n",
      "[🟠] Training...\n",
      "ep     1 | L=2.52e-01 | lr=1.0e-03\n",
      "\n",
      "[🟠] Inferencing...\n",
      "\n",
      "[🟠] Computing Coverage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 382.91it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 261.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[✅] Data Loss = 5.932e-03\n",
      "\n",
      "[🔎] Trying: {'epochs': 100, 'λ_pde': 2.0, 'λ_ic': 5.0, 'λ_data': 1.0, 'lr': 0.001, 'stop_schedule': 20000}\n",
      "\n",
      "[🟠] Training...\n",
      "ep     1 | L=2.97e-01 | lr=1.0e-03\n",
      "\n",
      "[🟠] Inferencing...\n",
      "\n",
      "[🟠] Computing Coverage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 486.71it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 216.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[✅] Data Loss = 7.806e-03\n",
      "\n",
      "[🔎] Trying: {'epochs': 100, 'λ_pde': 2.0, 'λ_ic': 5.0, 'λ_data': 2.5, 'lr': 0.001, 'stop_schedule': 20000}\n",
      "\n",
      "[🟠] Training...\n",
      "ep     1 | L=3.36e-01 | lr=1.0e-03\n",
      "\n",
      "[🟠] Inferencing...\n",
      "\n",
      "[🟠] Computing Coverage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 560.42it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 332.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[✅] Data Loss = 6.149e-03\n",
      "\n",
      "[🔎] Trying: {'epochs': 100, 'λ_pde': 2.0, 'λ_ic': 5.0, 'λ_data': 5.0, 'lr': 0.001, 'stop_schedule': 20000}\n",
      "\n",
      "[🟠] Training...\n",
      "ep     1 | L=2.99e-01 | lr=1.0e-03\n",
      "\n",
      "[🟠] Inferencing...\n",
      "\n",
      "[🟠] Computing Coverage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 487.21it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 251.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[✅] Data Loss = 5.751e-03\n",
      "\n",
      "[🔎] Trying: {'epochs': 100, 'λ_pde': 2.0, 'λ_ic': 10.0, 'λ_data': 1.0, 'lr': 0.001, 'stop_schedule': 20000}\n",
      "\n",
      "[🟠] Training...\n",
      "ep     1 | L=2.85e-01 | lr=1.0e-03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 125\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils_tools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils_result_viz\u001b[39;00m   \u001b[38;5;28;01mimport\u001b[39;00m plot_1D_comparison_with_coverage, plot_2D_comparison_with_coverage, plot_metrics_table\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils_tools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils_result_metrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dist_test_uncertainties\n\u001b[0;32m--> 125\u001b[0m \u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_title\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDistance CP Model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Change this\u001b[39;49;00m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Model Fitting & Predicting\u001b[39;49;00m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43muqmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdist_pinn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Change this|\u001b[39;49;00m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_kwargs_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline_pred_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline_pred_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcp_pred_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcp_pred_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrue_solution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpde\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrue_solution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Coverage Test\u001b[39;49;00m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbaseline_testing_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline_testing_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcp_testing_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcp_testing_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbaseline_test_uncertainties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdist_test_uncertainties\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Change this\u001b[39;49;00m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Plotting function\u001b[39;49;00m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplotting_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_metrics_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# \u001b[39;49;00m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2dpoisson_dist_cp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Change this\u001b[39;49;00m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_vis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_vis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_test\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/PINN UQ/utils_tools/utils_tuning.py:99\u001b[0m, in \u001b[0;36mhyperparameter_tuning\u001b[0;34m(plot_title, uqmodel, alpha, X_test, Y_test, fit_args, fit_kwargs_grid, baseline_pred_kwargs, cp_pred_kwargs, true_solution, baseline_testing_args, cp_testing_args, baseline_test_uncertainties, plotting_func, save_dir, X_vis, Y_vis, X_validation, Y_validation)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Baseline Model\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[🟠] Training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 99\u001b[0m baseline_loss_dict \u001b[38;5;241m=\u001b[39m \u001b[43muqmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhyperparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Compute the baseline model's data loss\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X_validation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m (Y_validation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[0;32m~/Desktop/PINN UQ/utils_uqmd/utils_uq_distance.py:101\u001b[0m, in \u001b[0;36mDistanceUQPINN.fit\u001b[0;34m(self, X_train, Y_train, coloc_pt_num, λ_pde, λ_ic, λ_bc, λ_data, epochs, lr, print_every, scheduler_cls, scheduler_kwargs, stop_schedule)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpde, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mic_loss\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     99\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m λ_ic \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpde\u001b[38;5;241m.\u001b[39mic_loss(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 101\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m; opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ep \u001b[38;5;241m%\u001b[39m print_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m ep \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m5d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | L=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopt\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cp/lib/python3.10/site-packages/torch/_tensor.py:639\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m        used to compute the :attr:`tensors`.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    650\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/cp/lib/python3.10/site-packages/torch/overrides.py:1721\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1718\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1721\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1723\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/cp/lib/python3.10/site-packages/torch/utils/_device.py:104\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cp/lib/python3.10/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cp/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cp/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basic\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "# PDEi\n",
    "from utils_pde.utils_pde_2dpoisson import Poisson2D\n",
    "\n",
    "# Viz\n",
    "from utils_tools.utils_result_viz import plot_predictions_2D\n",
    "\n",
    "# Base Mdoels\n",
    "from utils_uqmd.utils_uq_dropout import DropoutPINN\n",
    "from utils_uqmd.utils_uq_mlp import MLPPINN\n",
    "from utils_uqmd.utils_uq_vi import VIBPINN\n",
    "from utils_uqmd.utils_uq_distance import DistanceUQPINN\n",
    "\n",
    "# CP\n",
    "from utils_uqmd.utils_uq_cp import CP\n",
    "\n",
    "# Ensure reproducibility\n",
    "import random, numpy as np, torch\n",
    "seed = 12345\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Data Noise\n",
    "data_noise = 0.05\n",
    "\n",
    "# Define PDE\n",
    "domain=((0.0, 1.0), (0.0, 1.0))\n",
    "true_solution=lambda xy: torch.sin(math.pi * xy[..., 0:1]) * torch.sin(math.pi * xy[..., 1:2])\n",
    "pde = Poisson2D(domain, true_solution)\n",
    "\n",
    "# Generate training and testing data of the poisson function\n",
    "(X_train, Y_train) = pde.data_generation(500, data_noise)\n",
    "(X_test, Y_test) = pde.data_generation(100, data_noise)\n",
    "(X_calibration, Y_calibration) = pde.data_generation(200, data_noise)\n",
    "\n",
    "# Number of colocation point\n",
    "colloc_pt_num = 100\n",
    "\n",
    "# Generating alphas to test\n",
    "from utils_tools.utils_result_metrics import generating_alphas\n",
    "alphas = generating_alphas(20)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 4. Build Dropout-PINN (1 input → 1 output)\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "from utils_uqmd.utils_uq_dropout import DropoutPINN\n",
    "\n",
    "model_args = {\n",
    "    \"pde_class\":pde,\n",
    "    \"input_dim\":3,\n",
    "    \"hidden_dims\":[64, 128, 265, 265, 128, 64],\n",
    "    \"output_dim\":1,\n",
    "}\n",
    "\n",
    "dist_pinn = DistanceUQPINN(**model_args)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 5. Hyper-parameter grid & CP settings\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "fit_args = dict(coloc_pt_num=200, X_train=X_train, Y_train=Y_train)\n",
    "fit_kwargs_grid = dict(\n",
    "    epochs=[100, 20000, 40000, 60000],\n",
    "    λ_pde=[1.0, 2.0, 3.0, 5.0, 9.0], λ_ic=[5.0, 10.0], λ_data=[1.0, 2.50, 5.0],\n",
    "    lr=[1e-3], stop_schedule=[20000]\n",
    ")\n",
    "\n",
    "baseline_pred_kwargs = dict(n_samples=200)\n",
    "\n",
    "\n",
    "from utils_uqmd.utils_uq_cp import CP\n",
    "\n",
    "# CP Model\n",
    "cp_pred_kwargs = {\n",
    "        \"X_train\":X_train,  \"Y_train\":Y_train,\n",
    "        \"X_cal\":X_calibration, \"Y_cal\":Y_calibration,\n",
    "        \"heuristic_u\":\"raw_std\",  # Change this based on cp\n",
    "        \"k\":10\n",
    "}\n",
    "\n",
    "cp_testing_args = {\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"heuristic_u\":\"raw_std\", # Change base on if the baseline cp\n",
    "    \"k\":10\n",
    "}\n",
    "\n",
    "baseline_testing_args = { \n",
    "    \"uqmodel\":dist_pinn,   # Change this\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test,\n",
    "    \"heuristic_u\":\"feature\",\n",
    "    \"n_samples\":200, \n",
    "}\n",
    "\n",
    "# --------------------------------------------\n",
    "# Defining Plotting Grid\n",
    "# --------------------------------------------\n",
    "n_grid = 100\n",
    "x = torch.linspace(0, 1, n_grid)\n",
    "y = torch.linspace(0, 1, n_grid)\n",
    "X, Y = torch.meshgrid(x, y, indexing='xy')\n",
    "grid_test = torch.cat([X.reshape(-1, 1), Y.reshape(-1, 1)], dim=1)\n",
    "\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 6. Launch tuning with the NEW 1-D coverage plot\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "from utils_tools.utils_tuning       import hyperparameter_tuning\n",
    "from utils_tools.utils_result_viz   import plot_1D_comparison_with_coverage, plot_2D_comparison_with_coverage, plot_metrics_table\n",
    "from utils_tools.utils_result_metrics import dist_test_uncertainties\n",
    "\n",
    "hyperparameter_tuning(\n",
    "    plot_title=\"Distance CP Model\", # Change this\n",
    "    # Model Fitting & Predicting\n",
    "    uqmodel=dist_pinn,  # Change this|\n",
    "    alpha=0.05, \n",
    "    X_test=grid_test, Y_test=Y_test, \n",
    "    fit_args=fit_args, fit_kwargs_grid=fit_kwargs_grid, baseline_pred_kwargs=baseline_pred_kwargs, cp_pred_kwargs=cp_pred_kwargs, \n",
    "    true_solution=pde.true_solution,\n",
    "    # Coverage Test\n",
    "    baseline_testing_args=baseline_testing_args, cp_testing_args=cp_testing_args,\n",
    "    baseline_test_uncertainties=dist_test_uncertainties, # Change this\n",
    "    # Plotting function\n",
    "    plotting_func=plot_metrics_table, # \n",
    "    save_dir=\"2dpoisson_dist_cp\", # Change this\n",
    "    X_vis=X_train, Y_vis=Y_train,\n",
    "    X_validation=X_test, Y_validation=Y_test\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
